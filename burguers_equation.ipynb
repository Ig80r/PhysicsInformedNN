{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Maziar Raissi\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp  # For L-BFGS optimizer\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "class PhysicsInformedNN:\n",
    "    \n",
    "    # Initialize the class\n",
    "    def __init__(self, X_u, u, X_f, layers, lb, ub, nu):\n",
    "\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "\n",
    "        self.x_u = X_u[:, 0:1]\n",
    "        self.t_u = X_u[:, 1:2]\n",
    "\n",
    "        self.x_f = X_f[:, 0:1]\n",
    "        self.t_f = X_f[:, 1:2]\n",
    "\n",
    "        self.u = u\n",
    "\n",
    "        self.layers = layers\n",
    "        self.nu = nu\n",
    "\n",
    "        # Initialize NNs\n",
    "        self.model = self.initialize_NN(layers)\n",
    "\n",
    "        # Convert data to tensors\n",
    "        self.x_u_tf = tf.convert_to_tensor(self.x_u, dtype=tf.float32)\n",
    "        self.t_u_tf = tf.convert_to_tensor(self.t_u, dtype=tf.float32)\n",
    "        self.u_tf = tf.convert_to_tensor(self.u, dtype=tf.float32)\n",
    "\n",
    "        self.x_f_tf = tf.convert_to_tensor(self.x_f, dtype=tf.float32)\n",
    "        self.t_f_tf = tf.convert_to_tensor(self.t_f, dtype=tf.float32)\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    def initialize_NN(self, layers):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
    "        for width in layers[1:-1]:\n",
    "            model.add(tf.keras.layers.Dense(width, activation='tanh',\n",
    "                                            kernel_initializer='glorot_normal'))\n",
    "        model.add(tf.keras.layers.Dense(layers[-1], activation=None))\n",
    "        return model\n",
    "\n",
    "    def net_u(self, x, t):\n",
    "        X = tf.concat([x, t], 1)\n",
    "        X = 2.0 * (X - self.lb) / (self.ub - self.lb) - 1.0\n",
    "        u = self.model(X)\n",
    "        return u\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        with tf.GradientTape(persistent=True) as tape2:\n",
    "            tape2.watch([x, t])\n",
    "            with tf.GradientTape(persistent=True) as tape1:\n",
    "                tape1.watch([x, t])\n",
    "                u = self.net_u(x, t)\n",
    "            u_x = tape1.gradient(u, x)\n",
    "            u_t = tape1.gradient(u, t)\n",
    "        u_xx = tape2.gradient(u_x, x)\n",
    "        del tape1\n",
    "        del tape2\n",
    "        f = u_t + u * u_x - self.nu * u_xx\n",
    "        return f\n",
    "\n",
    "    @tf.function\n",
    "    def loss_fn(self):\n",
    "        u_pred = self.net_u(self.x_u_tf, self.t_u_tf)\n",
    "        f_pred = self.net_f(self.x_f_tf, self.t_f_tf)\n",
    "        loss = tf.reduce_mean(tf.square(self.u_tf - u_pred)) + \\\n",
    "               tf.reduce_mean(tf.square(f_pred))\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = self.loss_fn()\n",
    "        gradients = tape.gradient(loss_value, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        return loss_value\n",
    "\n",
    "    def train(self, nIter):\n",
    "        for iter in range(nIter):\n",
    "            loss_value = self.train_step()\n",
    "            if iter % 100 == 0:\n",
    "                print('Iter %d, Loss: %.5e' % (iter, loss_value.numpy()))\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        x = tf.convert_to_tensor(X_star[:, 0:1], dtype=tf.float32)\n",
    "        t = tf.convert_to_tensor(X_star[:, 1:2], dtype=tf.float32)\n",
    "        u_pred = self.net_u(x, t)\n",
    "        f_pred = self.net_f(x, t)\n",
    "        return u_pred.numpy(), f_pred.numpy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    nu = 0.01/np.pi\n",
    "    noise = 0.0\n",
    "\n",
    "    N_u = 100\n",
    "    N_f = 10000\n",
    "    layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "\n",
    "    data = scipy.io.loadmat('Data/burgers_shock.mat')\n",
    "\n",
    "    t = data['t'].flatten()[:,None]\n",
    "    x = data['x'].flatten()[:,None]\n",
    "    Exact = np.real(data['usol']).T\n",
    "\n",
    "    X, T = np.meshgrid(x,t)\n",
    "\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    u_star = Exact.flatten()[:,None]\n",
    "\n",
    "    # Domain bounds\n",
    "    lb = X_star.min(0)\n",
    "    ub = X_star.max(0)\n",
    "\n",
    "    xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "    uu1 = Exact[0:1,:].T\n",
    "    xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
    "    uu2 = Exact[:,0:1]\n",
    "    xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
    "    uu3 = Exact[:,-1:]\n",
    "\n",
    "    X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "    u_train = np.vstack([uu1, uu2, uu3])\n",
    "\n",
    "    idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "    X_u_train = X_u_train[idx, :]\n",
    "    u_train = u_train[idx,:]\n",
    "\n",
    "    X_f_train = lb + (ub - lb) * lhs(2, N_f)\n",
    "    X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "\n",
    "    model = PhysicsInformedNN(X_u_train, u_train, X_f_train, layers, lb, ub, nu)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.train(10000)  # Adjust the number of iterations as needed\n",
    "    elapsed = time.time() - start_time\n",
    "    print('Training time: %.4f' % (elapsed))\n",
    "\n",
    "    u_pred, f_pred = model.predict(X_star)\n",
    "\n",
    "    error_u = np.linalg.norm(u_star - u_pred, 2)/np.linalg.norm(u_star, 2)\n",
    "    print('Error u: %e' % (error_u))\n",
    "\n",
    "    U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "    Error = np.abs(Exact - U_pred)\n",
    "\n",
    "    ######################################################################\n",
    "    ############################# Plotting ###############################\n",
    "    ######################################################################\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "\n",
    "    ####### Row 0: u(t,x) ##################\n",
    "    gs0 = gridspec.GridSpec(1, 2)\n",
    "    gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
    "    ax = plt.subplot(gs0[:, :])\n",
    "\n",
    "    h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow',\n",
    "                  extent=[t.min(), t.max(), x.min(), x.max()],\n",
    "                  origin='lower', aspect='auto')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(h, cax=cax)\n",
    "\n",
    "    ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
    "\n",
    "    line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
    "    ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "\n",
    "    ax.set_xlabel('$t$')\n",
    "    ax.set_ylabel('$x$')\n",
    "    ax.legend(frameon=False, loc = 'best')\n",
    "    ax.set_title('$u(t,x)$', fontsize = 10)\n",
    "\n",
    "    ####### Row 1: u(t,x) slices ##################\n",
    "    gs1 = gridspec.GridSpec(1, 3)\n",
    "    gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
    "\n",
    "    ax = plt.subplot(gs1[0, 0])\n",
    "    ax.plot(x,Exact[25,:], 'b-', linewidth = 2, label = 'Exact')\n",
    "    ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(t,x)$')\n",
    "    ax.set_title('$t = 0.25$', fontsize = 10)\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-1.1,1.1])\n",
    "\n",
    "    ax = plt.subplot(gs1[0, 1])\n",
    "    ax.plot(x,Exact[50,:], 'b-', linewidth = 2, label = 'Exact')\n",
    "    ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(t,x)$')\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-1.1,1.1])\n",
    "    ax.set_title('$t = 0.50$', fontsize = 10)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
    "\n",
    "    ax = plt.subplot(gs1[0, 2])\n",
    "    ax.plot(x,Exact[75,:], 'b-', linewidth = 2, label = 'Exact')\n",
    "    ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(t,x)$')\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-1.1,1.1])\n",
    "    ax.set_title('$t = 0.75$', fontsize = 10)\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
